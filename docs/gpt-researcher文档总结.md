# GPT-Researcher æ–‡æ¡£ç ”ç©¶æ€»ç»“

åŸºäºå®˜æ–¹æ–‡æ¡£çš„æ·±åº¦åˆ†æ

---

## ä¸€ã€Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰æœºåˆ¶

### 1.1 æ•°æ®æ¥æºç±»å‹

GPT-Researcher æ”¯æŒ **5 ç§ä¸Šä¸‹æ–‡æ¥æº**ï¼š

| æ¥æºç±»å‹ | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|---------|------|----------|
| **web** | é»˜è®¤ï¼Œä»äº’è”ç½‘æœç´¢ | é€šç”¨ç½‘ç»œç ”ç©¶ |
| **local** | æœ¬åœ°æ–‡æ¡£ | ä¼ä¸šçŸ¥è¯†åº“ã€ä¸ªäººæ–‡æ¡£ |
| **static** | æŒ‡å®š URL åˆ—è¡¨ | é’ˆå¯¹ç‰¹å®šç½‘ç«™ç ”ç©¶ |
| **langchain_documents** | LangChain Document å¯¹è±¡ | ç¨‹åºåŒ–æ•°æ®å¯¼å…¥ |
| **langchain_vectorstore** | å‘é‡æ•°æ®åº“ | RAG åº”ç”¨ã€çŸ¥è¯†åº“ |
| **hybrid** | æ··åˆæ¨¡å¼ | æœ¬åœ° + ç½‘ç»œç»“åˆ |

---

### 1.2 æ ¸å¿ƒå·¥ä½œæµç¨‹

```
Step 1: å†…å®¹è½¬æ¢ä¸º LangChain Documents
    â†“
Step 2: Documents å­˜å…¥ VectorStore
    â†“
Step 3: ä¼ é€’ VectorStore ç»™ GPT-Researcher
```

**å…³é”®æŠ€æœ¯**ï¼š
- ä½¿ç”¨ **LangChain Documents** ä½œä¸ºæ ‡å‡†æ•°æ®æ ¼å¼
- ä½¿ç”¨ **LangChain VectorStores** è¿›è¡Œè¯­ä¹‰æ£€ç´¢
- æ”¯æŒæ‰€æœ‰ LangChain å…¼å®¹çš„å‘é‡æ•°æ®åº“ï¼ˆFAISSã€PGVectorã€Chroma ç­‰ï¼‰

---

### 1.3 å…·ä½“ç”¨æ³•ç¤ºä¾‹

#### (1) æŒ‡å®šæ¥æºç ”ç©¶

```python
from gpt_researcher import GPTResearcher

researcher = GPTResearcher(
    query="AI æœ€æ–°è¶‹åŠ¿",
    report_type="research_report",
    source_urls=[                          # æŒ‡å®šæ¥æº
        "https://en.wikipedia.org/...",
        "https://www.ibm.com/..."
    ],
    complement_source_urls=False           # ä»…ä½¿ç”¨æŒ‡å®šæ¥æº
)
```

#### (2) æœ¬åœ°æ–‡æ¡£ç ”ç©¶

```python
# ç¯å¢ƒå˜é‡
# DOC_PATH="./my-docs"

researcher = GPTResearcher(
    query="åŸºäºæˆ‘çš„æ–‡æ¡£åˆ†æ...",
    report_source="local"                  # æœ¬åœ°æ¨¡å¼
)
```

**æ”¯æŒæ ¼å¼**ï¼šPDFã€TXTã€CSVã€Excelã€Markdownã€PPTã€Word

#### (3) å‘é‡æ•°æ®åº“ç ”ç©¶

```python
from langchain_postgres.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings

vector_store = PGVector.from_existing_index(
    collection_name='my_docs',
    connection=CONNECTION_STRING,
    embeddings=OpenAIEmbeddings()
)

researcher = GPTResearcher(
    query="æŸ¥è¯¢é—®é¢˜",
    report_source="langchain_vectorstore",  # å‘é‡åº“æ¨¡å¼
    vector_store=vector_store
)
```

#### (4) æ··åˆæ¨¡å¼

```python
researcher = GPTResearcher(
    query="ç ”ç©¶é—®é¢˜",
    report_source="hybrid",                # æœ¬åœ° + ç½‘ç»œ
    vector_store=vector_store,             # æœ¬åœ°å‘é‡åº“
    query_domains=["wikipedia.org", ...]   # åŸŸåè¿‡æ»¤
)
```

---

### 1.4 æ•°æ®æ‘„å–æœ€ä½³å®è·µ

**ä½•æ—¶ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æ‘„å–æµç¨‹**ï¼š
- åµŒå…¥æ¨¡å‹è¾¾åˆ° API é€Ÿç‡é™åˆ¶
- VectorStore éœ€è¦é€Ÿç‡é™åˆ¶
- éœ€è¦è‡ªå®šä¹‰é™æµ/èŠ‚æµé€»è¾‘

**æ­¥éª¤**ï¼š
1. è½¬æ¢å†…å®¹ä¸º LangChain Documents
2. Documents åˆ†å—ï¼ˆå»ºè®® chunk_size=200, overlap=30ï¼‰
3. æ·»åŠ  metadataï¼ˆsourceã€titleã€file_path ç­‰ï¼‰
4. æ‰¹é‡æ’å…¥ VectorStoreï¼ˆå»ºè®®æ¯æ‰¹ 100 æ¡ï¼‰

---

### 1.5 åŸŸåè¿‡æ»¤

**æ”¯æŒçš„æ£€ç´¢å™¨**ï¼š
- âœ… Tavily
- âœ… Google Search

**ä½¿ç”¨æ–¹å¼**ï¼š

```python
# ä»£ç æ–¹å¼
researcher = GPTResearcher(
    query="AI åˆ›ä¸šå…¬å¸",
    query_domains=["forbes.com", "techcrunch.com"]
)

# URL å‚æ•°æ–¹å¼
https://app.gptr.dev/?domains=wikipedia.org,wired.com
```

---

## äºŒã€Multi-Agentsï¼ˆå¤šä»£ç†ï¼‰æ¶æ„

### 2.1 LangGraph å¤šä»£ç†ç³»ç»Ÿ

GPT-Researcher æä¾›äº†ä¸€ä¸ªåŸºäº **LangGraph** çš„å¤šä»£ç†åä½œç³»ç»Ÿï¼Œçµæ„Ÿæ¥è‡ª [STORM è®ºæ–‡](https://arxiv.org/abs/2402.14207)ã€‚

---

### 2.2 ä»£ç†å›¢é˜Ÿæ„æˆï¼ˆ7 ä¸ª AI ä»£ç†ï¼‰

| è§’è‰² | èŒè´£ | åŠŸèƒ½æè¿° |
|------|------|----------|
| **Human** | äººå·¥ç›‘ç£ | æä¾›åé¦ˆï¼Œç›‘ç£æµç¨‹ |
| **Chief Editor** | ä¸»ç¼–/åè°ƒå™¨ | åè°ƒæ‰€æœ‰ä»£ç†ï¼Œç®¡ç†å›¢é˜Ÿ |
| **Researcher** | ç ”ç©¶å‘˜ | æ‰§è¡Œæ·±åº¦ç ”ç©¶ï¼ˆgpt-researcherï¼‰ |
| **Editor** | ç¼–è¾‘ | è§„åˆ’ç ”ç©¶å¤§çº²å’Œç»“æ„ |
| **Reviewer** | å®¡ç¨¿äºº | éªŒè¯ç»“æœæ­£ç¡®æ€§ï¼Œæä¾›åé¦ˆ |
| **Revisor** | ä¿®è®¢è€… | æ ¹æ®åé¦ˆä¿®è®¢å†…å®¹ |
| **Writer** | ä½œè€… | ç¼–å†™æœ€ç»ˆæŠ¥å‘Š |
| **Publisher** | å‘å¸ƒè€… | å‘å¸ƒå¤šç§æ ¼å¼æŠ¥å‘Š |

---

### 2.3 å·¥ä½œæµç¨‹ï¼ˆ5 ä¸ªé˜¶æ®µï¼‰

```
1. è§„åˆ’é˜¶æ®µ (Planning)
    â””â”€â†’ Editor è§„åˆ’æŠ¥å‘Šç»“æ„

2. æ•°æ®æ”¶é›†åˆ†æ (Data Collection)
    â””â”€â†’ Researcher æ·±åº¦ç ”ç©¶ï¼ˆå¹¶è¡Œå¤„ç†å„å­ä¸»é¢˜ï¼‰

3. å®¡æŸ¥ä¿®è®¢ (Review & Revision)
    â”œâ”€â†’ Reviewer éªŒè¯
    â””â”€â†’ Revisor ä¿®è®¢ï¼ˆå¾ªç¯ç›´åˆ°æ»¡æ„ï¼‰

4. æ’°å†™æäº¤ (Writing)
    â””â”€â†’ Writer ç¼–å†™æœ€ç»ˆæŠ¥å‘Šï¼ˆå¼•è¨€ã€ç»“è®ºã€å‚è€ƒæ–‡çŒ®ï¼‰

5. å‘å¸ƒ (Publication)
    â””â”€â†’ Publisher å‘å¸ƒï¼ˆPDFã€DOCXã€Markdownï¼‰
```

---

### 2.4 æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Chief Editor                       â”‚
â”‚                  (ä¸»åè°ƒå™¨)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Initial    â”‚  â”‚    Editor    â”‚  â”‚   Writer     â”‚
â”‚   Research   â”‚  â”‚  (è§„åˆ’å¤§çº²)   â”‚  â”‚  (ç¼–å†™æŠ¥å‘Š)   â”‚
â”‚  (Browser)   â”‚  â”‚              â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â–¼                â–¼                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  Researcher   â”‚  â”‚  å­ä¸»é¢˜å¾ªç¯   â”‚        â”‚
â”‚ (æ·±åº¦ç ”ç©¶)    â”‚  â”‚  (å¹¶è¡Œå¤„ç†)   â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â”‚                â”‚                â”‚
        â–¼                â–¼                â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
   â”‚  æ¯ä¸ªå­ä¸»é¢˜:                 â”‚       â”‚
   â”‚    â”œâ”€â†’ Researcher ç ”ç©¶      â”‚       â”‚
   â”‚    â”œâ”€â†’ Reviewer éªŒè¯        â”‚â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ æœ€ç»ˆæŠ¥å‘Š
   â”‚    â””â”€â†’ Revisor ä¿®è®¢         â”‚       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  Publisher   â”‚  â”‚  Human       â”‚        â”‚
â”‚ (å¤šæ ¼å¼å‘å¸ƒ)  â”‚  â”‚ (äººå·¥åé¦ˆ)    â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
                                          â”‚
                                     (PDF/DOCX/MD)
```

---

### 2.5 é…ç½®æ–‡ä»¶ (task.json)

```json
{
  "query": "AI æ˜¯å¦å¤„äºç‚’ä½œå‘¨æœŸï¼Ÿ",
  "model": "gpt-4o",
  "max_sections": 3,                    // æœ€å¤§ç« èŠ‚æ•°
  "include_human_feedback": false,       // æ˜¯å¦äººå·¥å‚ä¸
  "source": "web",                       // web/local
  "follow_guidelines": true,             // éµå¾ªæŒ‡å—
  "guidelines": [                        // æŠ¥å‘ŠæŒ‡å—
    "å¿…é¡»å®Œæ•´å›ç­”åŸå§‹é—®é¢˜",
    "ä½¿ç”¨ APA æ ¼å¼",
    "ä½¿ç”¨è‹±è¯­æ’°å†™"
  ],
  "publish_formats": {                   // è¾“å‡ºæ ¼å¼
    "markdown": true,
    "pdf": true,
    "docx": true
  },
  "verbose": true
}
```

---

### 2.6 è¿è¡Œæ–¹å¼

#### æ–¹å¼ 1ï¼šæœ¬åœ°è¿è¡Œ

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# é…ç½®ç¯å¢ƒ
export OPENAI_API_KEY=xxx
export TAVILY_API_KEY=xxx

# è¿è¡Œ
python main.py
```

#### æ–¹å¼ 2ï¼šDocker éƒ¨ç½²

```bash
# æ„å»º
docker-compose up --build

# å¯åŠ¨æœåŠ¡
# - Python server: localhost:8000
# - React app: localhost:3000
```

#### æ–¹å¼ 3ï¼šLangGraph Cloud

```bash
pip install langgraph-cli
langgraph up
```

---

### 2.7 NextJS å‰ç«¯é›†æˆ

**æ–°å¢åŠŸèƒ½**ï¼š
- ğŸ“ æ‹–æ‹½ä¸Šä¼ æœ¬åœ°æ–‡æ¡£
- âš™ï¸ GUI ç¯å¢ƒå˜é‡é…ç½®
- ğŸ¤– è§¦å‘ multi_agents æµç¨‹
- ğŸ“Š ç¨³å®šæ€§ä¿®å¤

---

## ä¸‰ã€Deep Research æ¨¡å¼è¯¦è§£

### 3.1 æ ¸å¿ƒç‰¹æ€§

**æ ‘çŠ¶æ¢ç´¢æ¨¡å¼**ï¼š
- **Breadthï¼ˆå¹¿åº¦ï¼‰**ï¼šæ¯å±‚ç”Ÿæˆå¤šä¸ªæœç´¢æŸ¥è¯¢
- **Depthï¼ˆæ·±åº¦ï¼‰**ï¼šé€’å½’æ·±å…¥æ¢ç´¢
- **Concurrentï¼ˆå¹¶å‘ï¼‰**ï¼šå¼‚æ­¥å¹¶è¡Œå¤„ç†
- **Smart Contextï¼ˆæ™ºèƒ½ä¸Šä¸‹æ–‡ï¼‰**ï¼šè‡ªåŠ¨èšåˆå‘ç°

### 3.2 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **å®Œæˆæ—¶é—´** | ~5 åˆ†é’Ÿ |
| **æˆæœ¬** | ~$0.4 (o3-mini, high reasoning) |
| **è¾“å‡ºé•¿åº¦** | 2000+ è¯ |
| **æ·±åº¦å±‚æ•°** | 2-3 å±‚ï¼ˆå¯é…ç½®ï¼‰ |
| **å¹¿åº¦åˆ†æ”¯** | 4-5 ä¸ªï¼ˆå¯é…ç½®ï¼‰ |
| **å¹¶å‘æ•°** | 4 ä¸ªï¼ˆå¯é…ç½®ï¼‰ |

---

### 3.3 é…ç½®å‚æ•°

#### ç¯å¢ƒå˜é‡

```bash
DEEP_RESEARCH_BREADTH=5         # æ¯å±‚æŸ¥è¯¢æ•°
DEEP_RESEARCH_DEPTH=3           # ç ”ç©¶æ·±åº¦
DEEP_RESEARCH_CONCURRENCY=4     # å¹¶å‘æ•°
TOTAL_WORDS=2000               # æŠ¥å‘Šå­—æ•°
```

#### ä»£ç é…ç½®

```python
from gpt_researcher import GPTResearcher
from gpt_researcher.utils.enum import ReportType

researcher = GPTResearcher(
    query="é‡å­è®¡ç®—æœ€æ–°è¿›å±•",
    report_type=ReportType.DeepResearch.value,  # å…³é”®ï¼
    max_subtopics=7,
    tone="Analytical"
)

# æ‰§è¡Œæ·±åº¦ç ”ç©¶
await researcher.conduct_research()

# ç”ŸæˆæŠ¥å‘Š
report = await researcher.write_report()
```

---

### 3.4 è¿›åº¦è·Ÿè¸ª

```python
class ResearchProgress:
    current_depth: int       # å½“å‰æ·±åº¦
    total_depth: int         # æ€»æ·±åº¦
    current_breadth: int     # å½“å‰å¹¶è¡Œæ•°
    total_breadth: int       # æ€»å¹¶è¡Œæ•°
    current_query: str       # å½“å‰æŸ¥è¯¢
    completed_queries: int   # å·²å®ŒæˆæŸ¥è¯¢
    total_queries: int       # æ€»æŸ¥è¯¢æ•°
```

---

### 3.5 æœ€ä½³å®è·µ

1. **Start Broad** - ä»å®½æ³›æŸ¥è¯¢å¼€å§‹ï¼Œè®©ç³»ç»Ÿæ¢ç´¢ç»†èŠ‚
2. **Monitor Progress** - ä½¿ç”¨è¿›åº¦å›è°ƒäº†è§£æµç¨‹
3. **Adjust Parameters** - æ ¹æ®éœ€æ±‚è°ƒæ•´æ·±åº¦å’Œå¹¿åº¦
4. **Resource Management** - è€ƒè™‘ç³»ç»Ÿèµ„æºé™åˆ¶

---

## å››ã€ä¸æ ‡å‡†ç ”ç©¶çš„å¯¹æ¯”

| ç‰¹æ€§ | æ ‡å‡†ç ”ç©¶ | æ·±åº¦ç ”ç©¶ |
|------|-------------------|------------------|
| **report_type** | `research_report` | `deep` |
| **æœç´¢å±‚æ•°** | 1 å±‚ | 3 å±‚ï¼ˆå¯é…ç½®ï¼‰ |
| **å­ä¸»é¢˜æ•°** | 3-5 ä¸ª | 7+ ä¸ª |
| **å¹¶å‘æŸ¥è¯¢** | ä½ | é«˜ï¼ˆå¯é…ç½®ï¼‰ |
| **æ—¶é—´æˆæœ¬** | ~1 åˆ†é’Ÿ | ~5 åˆ†é’Ÿ |
| **é‡‘é’±æˆæœ¬** | ~$0.05 | ~$0.40 |
| **ä½¿ç”¨ LLM** | å¤šä¸ªæ··åˆ | STRATEGIC_LLM (o3-mini) |
| **é€‚ç”¨åœºæ™¯** | å¿«é€Ÿè°ƒç ” | å­¦æœ¯/æ·±åº¦åˆ†æ |

---

## äº”ã€æ ¸å¿ƒæ¶æ„æ´å¯Ÿ

### 5.1 æ•°æ®æµ

```
ç”¨æˆ·æŸ¥è¯¢
    â”‚
    â”œâ”€â†’ [ä¸Šä¸‹æ–‡é€‰æ‹©]
    â”‚   â”œâ”€â†’ web (ç½‘ç»œæœç´¢)
    â”‚   â”œâ”€â†’ local (æœ¬åœ°æ–‡æ¡£)
    â”‚   â”œâ”€â†’ static (æŒ‡å®š URL)
    â”‚   â”œâ”€â†’ vectorstore (å‘é‡åº“)
    â”‚   â””â”€â†’ hybrid (æ··åˆ)
    â”‚
    â”œâ”€â†’ [æ¨¡å¼é€‰æ‹©]
    â”‚   â”œâ”€â†’ standard (å•å±‚)
    â”‚   â””â”€â†’ deep (å¤šå±‚é€’è¿›)
    â”‚
    â”œâ”€â†’ [ç ”ç©¶æ‰§è¡Œ]
    â”‚   â”œâ”€â†’ ResearchConductor (æ ‡å‡†)
    â”‚   â””â”€â†’ DeepResearchSkill (æ·±åº¦)
    â”‚
    â”œâ”€â†’ [å¤šä»£ç†åä½œ] (å¯é€‰)
    â”‚   â”œâ”€â†’ Editor è§„åˆ’
    â”‚   â”œâ”€â†’ Researcher ç ”ç©¶
    â”‚   â”œâ”€â†’ Reviewer éªŒè¯
    â”‚   â”œâ”€â†’ Revisor ä¿®è®¢
    â”‚   â””â”€â†’ Writer ç¼–å†™
    â”‚
    â””â”€â†’ [æŠ¥å‘Šç”Ÿæˆ]
        â””â”€â†’ ReportGenerator
            â”œâ”€â†’ markdown
            â”œâ”€â†’ pdf
            â””â”€â†’ docx
```

---

### 5.2 å…³é”®æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯æ ˆ |
|------|--------|
| **LLM** | OpenAI, Anthropic, Ollama, ç­‰ 20+ |
| **Vector Store** | LangChain VectorStores (FAISS, PGVector, ç­‰) |
| **Embedding** | OpenAI, Cohere, HuggingFace, Ollama |
| **Multi-Agent** | LangGraph |
| **Web Scraper** | BeautifulSoup, Playwright |
| **Retriever** | Tavily, Google, Bing, DuckDuckGo, SearXNG, MCP |
| **Framework** | FastAPI, NextJS |

---

## å…­ã€å®æˆ˜å»ºè®®

### 6.1 é€‰æ‹©åˆé€‚çš„æ¨¡å¼

**ä½¿ç”¨æ ‡å‡†ç ”ç©¶** (`research_report`)ï¼š
- âœ… å¿«é€Ÿè°ƒç ”
- âœ… æˆæœ¬æ•æ„Ÿ
- âœ… æ—¥å¸¸ä¿¡æ¯æ”¶é›†

**ä½¿ç”¨æ·±åº¦ç ”ç©¶** (`deep`)ï¼š
- âœ… å­¦æœ¯ç ”ç©¶
- âœ… æ·±åº¦åˆ†æ
- âœ… æŠ¥å‘Š/è®ºæ–‡æ’°å†™
- âœ… ä¸é™æˆæœ¬

**ä½¿ç”¨å¤šä»£ç†** (LangGraph)ï¼š
- âœ… éœ€è¦äººå·¥ç›‘ç£
- âœ… å¤šè½®å®¡ç¨¿ä¿®è®¢
- âœ… é«˜è´¨é‡æŠ¥å‘Šè¾“å‡º

---

### 6.2 æˆæœ¬ä¼˜åŒ–ç­–ç•¥

1. **æ··åˆ LLM ç­–ç•¥**
   ```python
   FAST_LLM=ollama:llama3.2        # æœ¬åœ°ï¼Œå…è´¹
   SMART_LLM=openai:gpt-4o        # äº‘ç«¯ï¼Œå¼ºå¤§
   EMBEDDING=ollama:nomic-embed    # æœ¬åœ°ï¼ŒèŠ‚çœ
   ```

2. **è°ƒæ•´æ·±åº¦å‚æ•°**
   ```bash
   DEEP_RESEARCH_BREADTH=3         # é™ä½å¹¿åº¦
   DEEP_RESEARCH_DEPTH=2           # é™ä½æ·±åº¦
   DEEP_RESEARCH_CONCURRENCY=2     # é™ä½å¹¶å‘
   ```

3. **ä½¿ç”¨æœ¬åœ°æ£€ç´¢å™¨**
   - DuckDuckGoï¼ˆå…è´¹ï¼‰
   - SearXNGï¼ˆæœ¬åœ°éƒ¨ç½²ï¼‰
   - è€Œé Tavilyï¼ˆä»˜è´¹ï¼‰

---

### 6.3 è´¨é‡ä¼˜åŒ–ç­–ç•¥

1. **å¢åŠ å­ä¸»é¢˜æ•°**
   ```python
   max_subtopics=10
   ```

2. **ä½¿ç”¨åˆ†ææ€§è¯­æ°”**
   ```python
   tone="Analytical"  # æˆ– "Critical"
   ```

3. **å¯ç”¨å®¡æŸ¥ä¿®è®¢å¾ªç¯**ï¼ˆLangGraphï¼‰
   ```python
   "follow_guidelines": true,
   "include_human_feedback": true
   ```

4. **æ··åˆæ•°æ®æº**
   ```python
   report_source="hybrid",
   vector_store=custom_vectorstore,
   query_domains=["arxiv.org", "nature.com"]
   ```

---

## ä¸ƒã€æ€»ç»“

### ä¼˜åŠ¿

âœ… **æ¨¡å—åŒ–æ¶æ„** - Skills ç»„åˆï¼Œæ˜“äºæ‰©å±•
âœ… **çµæ´»çš„æ•°æ®æº** - æ”¯æŒ 5 ç§ä¸Šä¸‹æ–‡æ¥æº
âœ… **LangChain é›†æˆ** - å…¼å®¹ä¸°å¯Œç”Ÿæ€
âœ… **å¤šä»£ç†åä½œ** - LangGraph å®ç°
âœ… **æ·±åº¦ç ”ç©¶èƒ½åŠ›** - å¤šå±‚é€’è¿›æ¢ç´¢
âœ… **æˆæœ¬å¯æ§** - æ”¯æŒæœ¬åœ°+äº‘ç«¯æ··åˆ

### å±€é™

âš ï¸ **æˆæœ¬è¾ƒé«˜** - æ·±åº¦ç ”ç©¶ ~$0.4/æ¬¡
âš ï¸ **é€Ÿåº¦è¾ƒæ…¢** - æ·±åº¦ç ”ç©¶ ~5 åˆ†é’Ÿ
âš ï¸ **ä¾èµ–å¤–éƒ¨æœåŠ¡** - éœ€è¦ API Keys
âš ï¸ **è¯­è¨€é™åˆ¶** - è‹±æ–‡æ•ˆæœæœ€ä½³

### é€‚ç”¨åœºæ™¯

| åœºæ™¯ | æ¨èé…ç½® |
|------|---------|
| **æ—¥å¸¸å¿«é€Ÿè°ƒç ”** | `research_report` + DuckDuckGo |
| **å­¦æœ¯ç ”ç©¶** | `deep` + å¤šä»£ç† + `Analytical` è¯­æ°” |
| **ä¼ä¸šçŸ¥è¯†åº“** | `local` + `vectorstore` |
| **RAG åº”ç”¨** | `langchain_vectorstore` |
| **æ··åˆç ”ç©¶** | `hybrid` + è‡ªå®šä¹‰å‘é‡åº“ |
