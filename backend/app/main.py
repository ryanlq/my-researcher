"""
GPT Researcher - Simplified Backend
ç›´æ¥ä½¿ç”¨ gpt-researcher å®˜æ–¹åŒ…
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List
import json
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ - æŒ‡å®š backend ç›®å½•
backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
load_dotenv(os.path.join(backend_dir, '.env'))

# âœ¨ è®¾ç½® DOC_PATH ç¯å¢ƒå˜é‡ï¼ˆgpt-researcher éœ€è¦ï¼‰
import sys
from pathlib import Path
doc_path = Path(backend_dir) / 'data' / 'documents'
os.environ['DOC_PATH'] = str(doc_path)
print(f"ğŸ“ DOC_PATH è®¾ç½®ä¸º: {os.environ['DOC_PATH']}")

from gpt_researcher import GPTResearcher

# CORS é…ç½® - æ”¯æŒ JSON æ ¼å¼å’Œé€—å·åˆ†éš”æ ¼å¼
def parse_cors_origins():
    cors_origins_str = os.getenv("CORS_ORIGINS", "http://localhost:3000,http://localhost:8000")
    try:
        # å°è¯•è§£æ JSON æ ¼å¼
        import json
        return json.loads(cors_origins_str)
    except:
        # å¦åˆ™ç”¨é€—å·åˆ†å‰²
        return [origin.strip() for origin in cors_origins_str.split(",")]

CORS_ORIGINS = parse_cors_origins()

app = FastAPI(title="GPT Researcher API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ========== è¯·æ±‚/å“åº”æ¨¡å‹ ==========

class ResearchRequest(BaseModel):
    query: str = Field(..., description="ç ”ç©¶é—®é¢˜")
    report_type: str = Field(default="research_report", description="æŠ¥å‘Šç±»å‹")
    report_format: str = Field(default="markdown", description="æŠ¥å‘Šæ ¼å¼")
    tone: str = Field(default="objective", description="æŠ¥å‘Šè¯­æ°”")
    language: str = Field(default="chinese", description="æŠ¥å‘Šè¯­è¨€")


class ResearchResponse(BaseModel):
    report: str
    sources: List[str]
    costs: float
    images: List[str]


class CostEstimate(BaseModel):
    estimated_cost: float
    estimated_time_minutes: int
    estimated_queries: int


# ========== API ç«¯ç‚¹ ==========

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "GPT Researcher API",
        "version": "2.0 (Simplified)",
        "docs": "/docs"
    }


@app.post("/estimate", response_model=CostEstimate)
async def estimate_research(request: ResearchRequest):
    """
    ä¼°ç®—ç ”ç©¶æˆæœ¬å’Œæ—¶é—´

    åŸºäºæŸ¥è¯¢å¤æ‚åº¦ã€æŠ¥å‘Šç±»å‹å’Œç ”ç©¶æ¥æºæä¾›ä¼°ç®—
    """
    # åŸºç¡€ä¼°ç®—é€»è¾‘
    base_cost = 0.15
    base_time = 2  # åˆ†é’Ÿ
    base_queries = 10

    # æ ¹æ®æŠ¥å‘Šç±»å‹è°ƒæ•´
    if request.report_type == "deep":
        base_cost = 0.40
        base_time = 8
        base_queries = 75
    elif request.report_type == "multi_agent":
        base_cost = 0.80
        base_time = 20
        base_queries = 150

    # æ ¹æ®ç ”ç©¶æ¥æºè°ƒæ•´æˆæœ¬
    # æŒ‡å®šURLç ”ç©¶æˆæœ¬æ›´ä½ï¼Œå› ä¸ºä¸éœ€è¦é¢å¤–çš„æœç´¢
    if request.report_source == "static" and request.source_urls:
        if not request.complement_source_urls:
            # ä»…ç ”ç©¶æŒ‡å®šURLï¼Œæˆæœ¬å¤§å¹…é™ä½
            base_cost *= 0.4
            base_time *= 0.6
            base_queries = len(request.source_urls) * 2
        else:
            # æŒ‡å®šURL + å…¨ç½‘è¡¥å……ï¼Œæˆæœ¬é€‚ä¸­
            base_cost *= 0.7
            base_time *= 0.8

    # âœ¨ æœ¬åœ°æ–‡æ¡£ç ”ç©¶ - æˆæœ¬æä½
    elif request.report_source == "local" and request.document_ids:
        # ä»…å¤„ç†æœ¬åœ°æ–‡æ¡£ï¼Œæ— æœç´¢æˆæœ¬
        base_cost *= 0.2
        base_time *= 0.5
        base_queries = 0  # æ— éœ€æŸ¥è¯¢

    # âœ¨ æ··åˆç ”ç©¶ - URL + æœ¬åœ°æ–‡æ¡£
    elif request.report_source == "hybrid":
        if request.source_urls:
            # æœ‰URLå’Œæ–‡æ¡£ï¼Œæˆæœ¬é€‚ä¸­
            base_cost *= 0.5
            base_time *= 0.7
            base_queries = len(request.source_urls)
        else:
            # ä»…æ–‡æ¡£ï¼ŒåŒlocalæ¨¡å¼
            base_cost *= 0.2
            base_time *= 0.5
            base_queries = 0

    return CostEstimate(
        estimated_cost=round(base_cost, 2),
        estimated_time_minutes=int(base_time),
        estimated_queries=int(base_queries)
    )


@app.post("/research", response_model=ResearchResponse)
async def create_research(request: ResearchRequest):
    """
    åˆ›å»ºå¹¶æ‰§è¡Œç ”ç©¶ä»»åŠ¡

    ç›´æ¥ä½¿ç”¨ gpt-researcher å®˜æ–¹åŒ…æ‰§è¡Œç ”ç©¶
    """
    try:
        # æ„å»º GPTResearcher åŸºç¡€å‚æ•°
        researcher_kwargs = {
            "query": request.query,
            "report_type": request.report_type,
            "report_format": request.report_format,
            "tone": request.tone,
        }

        # å¤„ç†æŒ‡å®šæ¥æºç ”ç©¶
        if request.report_source and request.report_source != "web":
            # æŒ‡å®šURLç ”ç©¶ï¼ˆSTATIC æˆ– HYBRID æ¨¡å¼ï¼‰
            if request.source_urls:
                researcher_kwargs["source_urls"] = request.source_urls
                researcher_kwargs["complement_source_urls"] = request.complement_source_urls

            # âœ¨ æœ¬åœ°æ–‡æ¡£ç ”ç©¶
            if request.report_source in ["local", "hybrid"] and request.document_ids:
                # è®¾ç½® report_source å‚æ•°
                researcher_kwargs["report_source"] = request.report_source

        # åˆ›å»º GPT Researcher å®ä¾‹
        researcher = GPTResearcher(**researcher_kwargs)

        # æ‰§è¡Œç ”ç©¶
        await researcher.conduct_research()

        # ç”ŸæˆæŠ¥å‘Š
        report = await researcher.write_report()

        # è·å–é¢å¤–ä¿¡æ¯
        # ä½¿ç”¨ get_research_sources() è€Œä¸æ˜¯ get_source_urls()
        research_sources = researcher.get_research_sources()
        sources = [source.get("url") for source in research_sources if source.get("url")]
        costs = researcher.get_costs()
        images = researcher.get_research_images()

        return ResearchResponse(
            report=report,
            sources=sources or [],
            costs=costs or 0.0,
            images=images or []
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ç ”ç©¶æ‰§è¡Œå¤±è´¥: {str(e)}"
        )


@app.get("/research/{research_id}")
async def get_research(research_id: str):
    """
    è·å–ç ”ç©¶ç»“æœï¼ˆé¢„ç•™æ¥å£ï¼Œå½“å‰ä¸æ”¯æŒå†å²è®°å½•æŸ¥è¯¢ï¼‰
    """
    raise HTTPException(
        status_code=501,
        detail="å†å²è®°å½•æŸ¥è¯¢åŠŸèƒ½æœªå®ç°ï¼Œè¯·ä½¿ç”¨ /research ç«¯ç‚¹æ‰§è¡Œæ–°ç ”ç©¶"
    )


@app.get("/researches", response_model=List[dict])
async def list_researches():
    """
    åˆ—å‡ºç ”ç©¶å†å²ï¼ˆé¢„ç•™æ¥å£ï¼‰
    """
    return []


# ========== WebSocket ç«¯ç‚¹ ==========

@app.websocket("/ws/research")
async def research_websocket(websocket: WebSocket):
    """
    WebSocket ç«¯ç‚¹ç”¨äºå®æ—¶ç ”ç©¶è¿›åº¦æ›´æ–°ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰

    è¿æ¥åˆ°: ws://localhost:8000/ws/research

    å®¢æˆ·ç«¯æ¶ˆæ¯æ ¼å¼:
    {
        "query": "ç ”ç©¶é—®é¢˜",
        "report_type": "research_report",
        "report_format": "markdown",
        "tone": "objective",
        "report_source": "web" | "static",
        "source_urls": ["url1", "url2"],
        "complement_source_urls": false
    }

    æœåŠ¡å™¨æ¨é€äº‹ä»¶ï¼ˆç”± gpt-researcher è‡ªåŠ¨æ¨é€ï¼‰:
    - {"type": "logs", "content": "planning_research", "output": "ğŸŒ Browsing the web..."}
    - {"type": "logs", "content": "starting_research", "output": "ğŸ” Starting research..."}
    - {"type": "logs", "content": "research_step_finalized", "output": "âœ… Completed..."}
    - {"type": "completed", "report": "...", "sources": [...]}
    """
    await websocket.accept()

    try:
        # æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚
        data = await websocket.receive_json()

        query = data.get("query")
        report_type = data.get("report_type", "research_report")
        report_format = data.get("report_format", "markdown")
        tone = data.get("tone", "objective")
        report_source = data.get("report_source", "web")
        source_urls = data.get("source_urls")
        complement_source_urls = data.get("complement_source_urls", False)

        if not query:
            await websocket.send_json({
                "type": "error",
                "output": "Missing required field: query"
            })
            await websocket.close()
            return

        # æ„å»º researcher å‚æ•°
        researcher_kwargs = {
            "query": query,
            "report_type": report_type,
            "report_format": report_format,
            "tone": tone,
            "websocket": websocket,  # â­ å…³é”®ï¼šä¼ å…¥ websocket å¯ç”¨æµå¼è¾“å‡º
            "verbose": True          # â­ å¯ç”¨è¯¦ç»†æ—¥å¿—
        }

        # å¤„ç†æŒ‡å®šæ¥æºç ”ç©¶
        if report_source and report_source != "web":
            # æŒ‡å®šURLç ”ç©¶
            if source_urls:
                researcher_kwargs["source_urls"] = source_urls
                researcher_kwargs["complement_source_urls"] = complement_source_urls

            # âœ¨ æœ¬åœ°æ–‡æ¡£ç ”ç©¶
            document_ids = data.get("document_ids")
            if report_source in ["local", "hybrid"] and document_ids:
                researcher_kwargs["report_source"] = report_source

        # åˆ›å»º researcher å®ä¾‹
        researcher = GPTResearcher(**researcher_kwargs)

        # è°ƒè¯•ï¼šæ˜¾ç¤ºå®é™…ä½¿ç”¨çš„ retrievers
        print(f"ğŸ”§ DEBUG: Active retrievers: {[r.__name__ for r in researcher.retrievers]}")
        import os
        print(f"ğŸ”§ DEBUG: RETRIEVER env var: {os.getenv('RETRIEVER')}")
        print(f"ğŸ”§ DEBUG: Report source: {report_source}")
        print(f"ğŸ”§ DEBUG: Source URLs: {source_urls}")

        # æ‰§è¡Œç ”ç©¶ - gpt-researcher ä¼šè‡ªåŠ¨é€šè¿‡ websocket å‘é€è¿›åº¦æ›´æ–°
        await researcher.conduct_research()

        # ç”ŸæˆæŠ¥å‘Š
        report = await researcher.write_report()

        # è·å–ç»“æœ
        # ä½¿ç”¨ get_research_sources() è€Œä¸æ˜¯ get_source_urls()
        # å› ä¸º visited_urls å¯èƒ½ä¸ºç©ºï¼Œä½† research_sources åŒ…å«å®é™…çš„æŠ“å–æ•°æ®
        research_sources = researcher.get_research_sources()
        sources = [source.get("url") for source in research_sources if source.get("url")]
        costs = researcher.get_costs()
        images = researcher.get_research_images()

        # å‘é€å®Œæˆäº‹ä»¶
        await websocket.send_json({
            "type": "completed",
            "output": "âœ… ç ”ç©¶å®Œæˆï¼",
            "report": report,
            "sources": sources or [],
            "costs": costs or 0.0,
            "images": images or []
        })

    except WebSocketDisconnect:
        print("WebSocket client disconnected")
    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "output": f"âŒ ç ”ç©¶å¤±è´¥: {str(e)}"
        })
    finally:
        try:
            await websocket.close()
        except:
            pass


# ========== æ–‡æ¡£ç®¡ç†ç«¯ç‚¹ ==========

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

# ç›´æ¥å¯¼å…¥æ¨¡å—ï¼Œé¿å…è§¦å‘ __init__.py
import importlib.util
spec = importlib.util.spec_from_file_location(
    "documents",
    Path(__file__).parent / "api" / "v1" / "endpoints" / "documents.py"
)
documents_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(documents_module)

app.include_router(documents_module.router, prefix="/documents", tags=["documents"])


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        # WebSocket è¶…æ—¶é…ç½®
        websocket_ping_interval=20,      # æ¯20ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
        websocket_ping_timeout=60,       # å¿ƒè·³è¶…æ—¶60ç§’
        timeout_keep_alive=300,          # Keep-alive è¶…æ—¶5åˆ†é’Ÿ
    )
